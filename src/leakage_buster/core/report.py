
import os, json, datetime as dt
from typing import Dict
from jinja2 import Environment, FileSystemLoader, select_autoescape

def render_report(results: Dict, meta: Dict, out_dir: str):
    env = Environment(loader=FileSystemLoader(searchpath=os.path.join(os.path.dirname(__file__), "..", "templates")),
                      autoescape=select_autoescape())
    tpl = env.get_template("report.html.j2")
    html = tpl.render(results=results, meta=meta, now=dt.datetime.now().isoformat(timespec="seconds"))
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, "report.html")
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(html)
    return out_path

def write_fix_script(results: Dict, out_dir: str):
    os.makedirs(out_dir, exist_ok=True)
    path = os.path.join(out_dir, "fix_transforms.py")
    suggestions = []
    drop_cols = []
    group_cols = []
    te_cols = []
    window_cols = []
    
    for r in results.get("risks", []):
        risk_name = r["name"]
        evidence = r.get("evidence", {})
        
        if risk_name.startswith("Target leakage (high correlation)"):
            cols = list(evidence.get("columns", {}).keys())
            drop_cols.extend(cols)
            suggestions.append(f"# 高危：删除高相关泄漏列：{cols}")
            
        elif risk_name.startswith("Target encoding leakage"):
            cols = list(evidence.get("columns", {}).keys())
            te_cols.extend(cols)
            suggestions.append(f"# 高危：疑似目标编码泄漏列：{cols}")
            suggestions.append("# 建议：检查是否使用全量目标编码，改为CV内编码")
            
        elif risk_name.startswith("Time window leakage"):
            cols = list(evidence.get("columns", {}).keys())
            window_cols.extend(cols)
            suggestions.append(f"# 高危：疑似全量统计泄漏列：{cols}")
            suggestions.append("# 建议：改为仅使用窗口内可见数据的统计")
            
        elif risk_name.startswith("Target leakage (categorical purity)"):
            cols = list(evidence.get("columns", {}).keys())
            suggestions.append(f"# 中危：类别纯度异常列：{cols}")
            suggestions.append("# 建议：检查是否由目标聚合产生，考虑删除或重算")
            
        elif risk_name.startswith("KFold leakage risk"):
            candidates = [c["column"] for c in evidence.get("candidates", [])]
            group_cols.extend(candidates)
            suggestions.append(f"# 中危：建议用作GroupKFold的分组列：{candidates}")
            
        elif risk_name.startswith("CV strategy"):
            recommended = evidence.get("recommended", "")
            if recommended:
                suggestions.append(f"# 建议：使用 {recommended} CV策略")

    # 生成具体的修复代码
    content = f"""# Auto-generated by leakage-buster v0.2
# 时间泄漏/口径审计修复建议

import pandas as pd
import numpy as np
from sklearn.model_selection import GroupKFold, TimeSeriesSplit, KFold

def drop_leakage_columns(df):
    \"\"\"删除高危泄漏列\"\"\"
    drop_cols = {drop_cols}
    if drop_cols:
        print(f"删除泄漏列: {{drop_cols}}")
        df = df.drop(columns=drop_cols, errors='ignore')
    return df

def fix_target_encoding_features(df, target_col, te_cols=None):
    \"\"\"修复目标编码泄漏特征\"\"\"
    if te_cols is None:
        te_cols = {te_cols}
    
    # TODO: 实现CV内目标编码
    # 示例：使用 category_encoders 或手动实现CV内编码
    # from category_encoders import TargetEncoder
    # encoder = TargetEncoder(cols=te_cols)
    # df[te_cols] = encoder.fit_transform(df[te_cols], df[target_col])
    
    return df

def fix_time_window_features(df, time_col, window_cols=None):
    \"\"\"修复时间窗口泄漏特征\"\"\"
    if window_cols is None:
        window_cols = {window_cols}
    
    # TODO: 重新计算窗口内统计特征
    # 示例：使用滚动窗口而非全量统计
    # df = df.sort_values(time_col)
    # for col in window_cols:
    #     # 重新计算为滚动统计
    #     df[col + '_rolling'] = df.groupby('some_group')[target_col].transform(
    #         lambda x: x.rolling(window=30, min_periods=1).mean()
    #     )
    
    return df

def get_group_kfold_groups(df):
    \"\"\"返回GroupKFold分组\"\"\"
    group_candidates = {group_cols}
    if group_candidates:
        # 选择第一个候选列作为分组
        group_col = group_candidates[0]
        return df[group_col].values
    return None

def get_recommended_cv_splitter(df, target_col, time_col=None, cv_type=None):
    \"\"\"获取推荐的CV分割器\"\"\"
    if cv_type == 'timeseries' or (time_col and cv_type is None):
        return TimeSeriesSplit(n_splits=5)
    elif cv_type == 'group' or get_group_kfold_groups(df) is not None:
        groups = get_group_kfold_groups(df)
        return GroupKFold(n_splits=5), groups
    else:
        return KFold(n_splits=5, shuffle=True, random_state=42)

def apply_all_fixes(df, target_col, time_col=None):
    \"\"\"应用所有修复建议\"\"\"
    print("应用泄漏修复...")
    
    # 1. 删除高危泄漏列
    df = drop_leakage_columns(df)
    
    # 2. 修复目标编码特征
    df = fix_target_encoding_features(df, target_col)
    
    # 3. 修复时间窗口特征
    if time_col:
        df = fix_time_window_features(df, time_col)
    
    print("修复完成！")
    return df

# 使用示例：
# df_fixed = apply_all_fixes(df, target_col='your_target', time_col='your_time_col')
# cv_splitter = get_recommended_cv_splitter(df_fixed, 'your_target', 'your_time_col')

"""

    # 添加建议注释
    if suggestions:
        content += "\n# 详细建议：\n"
        content += "\n".join(suggestions) + "\n"
    
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return path

def write_meta(meta: Dict, out_dir: str):
    os.makedirs(out_dir, exist_ok=True)
    path = os.path.join(out_dir, "meta.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    return path

